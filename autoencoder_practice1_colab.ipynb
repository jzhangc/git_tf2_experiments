{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597958257789",
   "display_name": "Python 3.7.7 64-bit ('conda_venv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The complete annotation is in autoencoder_practice.py\n",
    "\"\"\"\n",
    "\n",
    "# ------ import modules ------\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.optimizers import SGD, Adam\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- model constuction ------\n",
    "# - autoencoder (complete model) -\n",
    "encoding_dim = 32  # compressed size\n",
    "\n",
    "# Below: input tensor object.\n",
    "input_img = Input(shape=(784, ))\n",
    "\n",
    "# Chain 1, encoding layer: from 784 to 32\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "\n",
    "# Chain 2, encoding layer: from 32 to 784\n",
    "# NOTE: 0,1 is the output format, simoid\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# - Final model -\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# - Seperate encoder model -\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# - Seperate decoder model -\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------ train the model ------\n",
    "# - compile/configure the models -\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# - load the MINST data -\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "\n",
    "# data rescaling to 0-1: min (0)-max(255) normalization\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# data reshape: 60000, 28, 28 -> 60000, 28*28 = 60000, 784\n",
    "x_train = x_train.reshape(len(x_train), np.prod(x_train.shape[1:]))\n",
    "x_test = x_test.reshape(len(x_test), np.prod(x_test.shape[1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/50\n60000/60000 [==============================] - 3s 52us/sample - loss: 0.6932 - val_loss: 0.6931\nEpoch 2/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6931 - val_loss: 0.6930\nEpoch 3/50\n60000/60000 [==============================] - 2s 40us/sample - loss: 0.6929 - val_loss: 0.6928\nEpoch 4/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6927 - val_loss: 0.6926\nEpoch 5/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6926 - val_loss: 0.6925\nEpoch 6/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6924 - val_loss: 0.6923\nEpoch 7/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6922 - val_loss: 0.6921\nEpoch 8/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6921 - val_loss: 0.6920\nEpoch 9/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6919 - val_loss: 0.6918\nEpoch 10/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6918 - val_loss: 0.6916\nEpoch 11/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6916 - val_loss: 0.6914\nEpoch 12/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6914 - val_loss: 0.6913\nEpoch 13/50\n60000/60000 [==============================] - 2s 40us/sample - loss: 0.6913 - val_loss: 0.6911\nEpoch 14/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6911 - val_loss: 0.6909\nEpoch 15/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6909 - val_loss: 0.6908\nEpoch 16/50\n60000/60000 [==============================] - 3s 42us/sample - loss: 0.6907 - val_loss: 0.6906\nEpoch 17/50\n60000/60000 [==============================] - 3s 42us/sample - loss: 0.6906 - val_loss: 0.6904\nEpoch 18/50\n60000/60000 [==============================] - 3s 42us/sample - loss: 0.6904 - val_loss: 0.6902\nEpoch 19/50\n60000/60000 [==============================] - 3s 42us/sample - loss: 0.6902 - val_loss: 0.6901\nEpoch 20/50\n60000/60000 [==============================] - 3s 42us/sample - loss: 0.6900 - val_loss: 0.6899\nEpoch 21/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6899 - val_loss: 0.6897\nEpoch 22/50\n60000/60000 [==============================] - 3s 42us/sample - loss: 0.6897 - val_loss: 0.6895\nEpoch 23/50\n60000/60000 [==============================] - 2s 42us/sample - loss: 0.6895 - val_loss: 0.6893\nEpoch 24/50\n60000/60000 [==============================] - 3s 42us/sample - loss: 0.6893 - val_loss: 0.6891\nEpoch 25/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6891 - val_loss: 0.6889\nEpoch 26/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6889 - val_loss: 0.6887\nEpoch 27/50\n60000/60000 [==============================] - 3s 42us/sample - loss: 0.6887 - val_loss: 0.6885\nEpoch 28/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6885 - val_loss: 0.6883\nEpoch 29/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6883 - val_loss: 0.6881\nEpoch 30/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6881 - val_loss: 0.6879\nEpoch 31/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6879 - val_loss: 0.6877\nEpoch 32/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6877 - val_loss: 0.6874\nEpoch 33/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6875 - val_loss: 0.6872\nEpoch 34/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6872 - val_loss: 0.6870\nEpoch 35/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6870 - val_loss: 0.6867\nEpoch 36/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6868 - val_loss: 0.6865\nEpoch 37/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6865 - val_loss: 0.6863\nEpoch 38/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6863 - val_loss: 0.6860\nEpoch 39/50\n60000/60000 [==============================] - 2s 42us/sample - loss: 0.6860 - val_loss: 0.6857\nEpoch 40/50\n60000/60000 [==============================] - 2s 42us/sample - loss: 0.6858 - val_loss: 0.6855\nEpoch 41/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6855 - val_loss: 0.6852\nEpoch 42/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6852 - val_loss: 0.6849\nEpoch 43/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6850 - val_loss: 0.6846\nEpoch 44/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6847 - val_loss: 0.6843\nEpoch 45/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6844 - val_loss: 0.6840\nEpoch 46/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6841 - val_loss: 0.6837\nEpoch 47/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6838 - val_loss: 0.6834\nEpoch 48/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6835 - val_loss: 0.6831\nEpoch 49/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6831 - val_loss: 0.6828\nEpoch 50/50\n60000/60000 [==============================] - 2s 41us/sample - loss: 0.6828 - val_loss: 0.6824\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x104b0a68d0>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# - fit the model -\n",
    "# early stop\n",
    "earlystop_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "callbacks = [earlystop_callback] # callback is a list\n",
    "\n",
    "# fitting\n",
    "\"\"\"\n",
    "input, output = x_train,, x_train: because the input and outpout are the same for autoencoder \n",
    "batch_size: we don't set the number of batches. Instead, we set batch_size, which will determine the number of batches\n",
    "    given the total sample number. \n",
    "\"\"\"\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ display resutls ------\n",
    "# - predict -\n",
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)  # get the encoded image\n",
    "decoded_imgs = decoder.predict(encoded_imgs)  # decode the encoded image\n",
    "\n",
    "# - visulization -\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}