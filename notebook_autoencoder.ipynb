{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The complete annotation is in autoencoder_practice.py\n",
    "\"\"\"\n",
    "\n",
    "# ------ import modules ------\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# import tensorflow.python.util.deprecation as deprecation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "from tqdm import tqdm\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "mlcompute.set_mlc_device(device_name=\"gpu\")\n",
    "# deprecation._PRINT_DEPRECATION_WARNINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- model constuction ------\n",
    "class Encoder(Layer):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.output_dim = 16\n",
    "        self.hidden_layer1 = Dense(\n",
    "            units=latent_dim, activation='relu', kernel_initializer='he_uniform')\n",
    "        self.hidden_layer2 = Dense(units=32, activation='relu')\n",
    "        self.output_layer = Dense(units=self.output_dim, activation='sigmoid')\n",
    "\n",
    "    def call(self, input_dim):\n",
    "        x = self.hidden_layer1(input_dim)\n",
    "        x = self.hidden_layer2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(Layer):\n",
    "    def __init__(self, latent_dim, original_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_layer1 = Dense(\n",
    "            units=latent_dim, activation='relu', kernel_initializer='he_uniform')\n",
    "        self.hidden_layer2 = Dense(units=32, activation='relu')\n",
    "        self.output_layer = Dense(units=original_dim, activation='sigmoid')\n",
    "\n",
    "    def call(self, encoded_dim):\n",
    "        x = self.hidden_layer1(encoded_dim)\n",
    "        x = self.hidden_layer2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class autoencoder_decoder(Model):\n",
    "    def __init__(self, original_dim, latent_dim):\n",
    "        super(autoencoder_decoder, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim=latent_dim)\n",
    "        self.decoder = Decoder(latent_dim=self.encoder.output_dim,\n",
    "                               original_dim=original_dim)\n",
    "\n",
    "    def call(self, input_dim):\n",
    "        x = self.encoder(input_dim)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ data ------\n",
    "# -- loading data --\n",
    "# x_train: 60000, 28, 28. no need to have y\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "# -- data transformation and normalization --\n",
    "x_train, x_test = x_train.astype('float32') / 255, x_test.astype(\n",
    "    'float32') / 255  # transform from int to float and min(0.0)-max(255.0) normalization into 0-1\n",
    "\n",
    "# -- data vectorization: 28*28 = 784 --\n",
    "# ndarray.shape: x, y, z. index: [0, 1, 2]. so y and z are ndarray.shape[1:]\n",
    "x_train = x_train.reshape(len(x_train), np.prod(x_train.shape[1:]))\n",
    "x_test = x_test.reshape(len(x_test), np.prod(x_test.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------ training ------\n",
    "# -- early stop and optimizer --\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "callbacks = [earlystop]\n",
    "optm = Adam(learning_rate=0.001)\n",
    "\n",
    "# -- model --\n",
    "m = autoencoder_decoder(original_dim=x_train.shape[1], latent_dim=64)\n",
    "# the output is sigmoid, therefore binary_crossentropy\n",
    "m.compile(optimizer=optm, loss=\"binary_crossentropy\")\n",
    "\n",
    "# -- training --\n",
    "m.fit(x=x_train, y=x_train, batch_size=256, epochs=100, callbacks=callbacks,\n",
    "      shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ inspection ------\n",
    "reconstruction_test = m.predict(x_test)\n",
    "\n",
    "# - visulization -\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstruction_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8  (conda)",
   "name": "pythonjvsc74a57bd0f6abfb86dc54f951e1d6f2a3840fc2d7e883f15fe9e1bff07aebbf13b5d15bf8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "f6abfb86dc54f951e1d6f2a3840fc2d7e883f15fe9e1bff07aebbf13b5d15bf8"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}